###Introduction
#read in Breast cancer dataset
install.packages("tidyverse")
library(tidyverse)
BC_data <- read_tsv("GSE96058_expression_matrix_3decimals.tsv", n_max = 1000)

#read in textfile dataset
textfile <- read_tsv("GSE96058_metadata.txt")
summary(textfile)

library(dplyr)
library(tidyr)
library(ggplot2)

###Preprocessing
#Missing-value summary for the metadata
missing_summary <- textfile %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variabele",
    values_to = "missing_count"
  ) %>%
  mutate(
    missing_percent = (missing_count / nrow(textfile)) * 100
  ) %>%
  arrange(desc(missing_percent))
missing_summary


#Plot of missing values for the metadata
ggplot(missing_summary,
       aes(x = reorder(variabele, missing_percent),
           y = missing_percent)) +
  geom_col(fill = "steelblue", color = "black", alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Percentage ontbrekende waarden per kolom",
    x = "Variabele",
    y = "Percentage missing (%)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    plot.title = element_text(face = "bold", size = 16)
  )
#treating the missing values
#removing ki67
clean <- textfile %>%
  select(-`ki67 status:ch1`)

# KNN imputation on the metadata
cleaned_data <- kNN(clean, k = 5, imp_var = FALSE)

#Missing-value summary for BC_data
missing_summary_BC <- BC_data %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "missing_count"
  ) %>%
  mutate(
    missing_percent = (missing_count / nrow(BC_data)) * 100
  ) %>%
  arrange(desc(missing_percent))

missing_summary_BC

#plot of the missing value summary for the BC_data
ggplot(missing_summary_BC,
       aes(x = reorder(variable, missing_percent),
           y = missing_percent)) +
  geom_col(fill = "steelblue", color = "black", alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Percentage ontbrekende waarden per kolom (BC_dataset)",
    x = "Variable",
    y = "Percentage missing (%)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    plot.title = element_text(face = "bold", size = 16)
  )

#preprocessing for making the merged dataset
colnames(BC_data)[1] <- 'title'
transposed_BC <- BC_data %>%
  column_to_rownames("title") %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column("title")

#making the merged dataset
merged_data <- left_join(cleaned_data, transposed_BC, by = "title")

merged_data

###univariate hypothesis
#univariate hypothesis preprocessing of data

#outliers
library(dplyr)

Q1 <- quantile(merged_data$ABHD11, 0.25, na.rm = TRUE)
Q3 <- quantile(merged_data$ABHD11, 0.75, na.rm = TRUE)
IQR_value <- IQR(merged_data$ABHD11, na.rm = TRUE)

lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

outliers <- merged_data %>%
  filter(ABHD11 < lower_bound | ABHD11 > upper_bound)

num_outliers <- nrow(outliers)
print(paste("Number of outliers:", num_outliers))

#boxplot with outlier detection
library(ggplot2)

ggplot(merged_data, aes(y = ABHD11, x = 1)) +
  
  geom_jitter(
    width = 0.2,
    alpha = 0.3,
    color = "grey50"
  ) +
  
  geom_boxplot(
    width = 0.3,
    outlier.color = "black",
    outlier.size = 1.5,
    fill = NA,
    color = "black"
  ) +
  
  labs(
    title = "ABHD11 expression",
    x = "",
    y = "ABHD11 expression"
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    plot.title = element_text(face = "bold")
  )

#histogram of the ABHD11 gene
library(ggplot2)

ggplot(merged_data, aes(x = ABHD11)) +
  geom_histogram(
    bins = 60,
    fill = "steelblue",
    color = "black",
    alpha = 0.7
  ) +
  labs(
    title = "Histogram of ABHD11",
    x = "ABHD11 expression",
    y = "Frequency"
  ) +
  theme_minimal(base_size = 14)

#univariate hypothesis test with restriction on tumor size
library(dplyr)
library(ggplot2)

# 1. Filter dataset for tumors < 2 cm
merged_data_2cm <- merged_data %>%
  filter(`tumor size:ch1` <= 2)

# 2. Linear regression model: tumor size ~ ABHD11
model <- lm(`tumor size:ch1` ~ ABHD11, data = merged_data_2cm)
summary(model)

# 3. Scatterplot + regressionline
ggplot(merged_data_2cm, aes(x = ABHD11, y = `tumor size:ch1`)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  labs(
    x = "ABHD11 expression",
    y = "Tumor size (cm)"
  ) +
  theme_minimal()

#univariate hypothesis test without restriction on tumor size
library(dplyr)
library(ggplot2)

# 1. Linear regression model: tumor size ~ ABHD11 on the complete dataset
model_full <- lm(`tumor size:ch1` ~ ABHD11, data = merged_data)
summary(model_full)

#figure of the linear regression
ggplot(merged_data, aes(x = ABHD11, y = `tumor size:ch1`)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  labs(
    x = "ABHD11 expression",
    y = "Tumor size (cm)"
  ) +
  theme_minimal()


###multivariate hypothesis
#t-SNE
# 1. Load required packages
library(matrixStats)
library(Rtsne)

set.seed(42)  #reproducibility

# Convert to numeric properly
BC_data <- as.data.frame(BC_data)

# Remove whitespace and convert all columns to numeric
BC_data[] <- lapply(BC_data, function(x) as.numeric(trimws(x)))

# 2. Ensure BC_data is a numeric matrix
# BC_data must be: rows = genes, columns = samples
BC_data <- as.matrix(BC_data)

# 3. Compute variance per gene (FAST)
gene_var <- rowVars(BC_data)              # numeric vector of variances
names(gene_var) <- rownames(BC_data)      # label variance values with gene names

# 4. Select top 1000 most variable genes
n_top <- min(1000, nrow(BC_data))         # if fewer than 1000 genes, adjust automatically
top_genes <- names(sort(gene_var, decreasing = TRUE))[1:n_top]

# 5. Subset the expression matrix to top genes
expr_top <- BC_data[top_genes, ]          # still genes x samples

# 6. Transpose to samples x genes (t-SNE expects samples as rows)
expr_top_t <- t(expr_top)

# 7. Scale expression values (z-score per gene)
expr_scaled <- scale(expr_top_t)

# 8. Run t-SNE (2 dimensions)
tsne_res <- Rtsne(
  expr_scaled,
  dims = 2,
  perplexity = 30,    # adjust depending on sample size
  verbose = TRUE,
  pca = FALSE
)

# 9. Create a dataframe with t-SNE coordinates
tsne_df <- data.frame(
  Sample = rownames(expr_scaled),
  TSNE1  = tsne_res$Y[,1],
  TSNE2  = tsne_res$Y[,2],
  stringsAsFactors = FALSE
)

head(tsne_df)

# 10. Create a scatter plot for the t_SNE
ggplot(tsne_df, aes(x = TSNE1, y = TSNE2)) +
  geom_point(color = "steelblue", size = 2, alpha = 0.7) +  # punten
  theme_minimal() +                                         # nette achtergrond
  labs(
    title = "t-SNE 2-Dimensional Digit Visualization",
    x = "t-SNE Dimension 1",
    y = "t-SNE Dimension 2"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title = element_text(size = 14)
  )
# 11. Merge t-SNE coordinates with merged_data on sample ID (F1, F2, F3,...)
tsne_merged <- merge(
  tsne_df,     
  merged_data,       
  by.x = "Sample",  
  by.y = "title",      
  all.x = TRUE
)
# 12. Create plots for the clinical variables of interest
#PLOT FOR CHEMOTHERAPY
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = factor(`chemo treated:ch1`))) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_manual(values = c("steelblue", "firebrick"), labels = c("No", "Yes")) +
  theme_minimal() +
  labs(title = "t-SNE colored by Chemo Treatment",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR SURVIVAL EVENT
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = factor(`overall survival event:ch1`))) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_manual(values = c("steelblue", "firebrick"), labels = c("No", "Yes")) +
  theme_minimal() +
  labs(title = "t-SNE colored by overall survival event",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR ER STATUS
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = factor(`er status:ch1`))) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_manual(values = c("steelblue", "firebrick"), labels = c("No", "Yes")) +
  theme_minimal() +
  labs(title = "t-SNE colored by ER status",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR HER2 STATUS
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = factor(`her2 status:ch1`))) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_manual(values = c("steelblue", "firebrick"), labels = c("No", "Yes")) +
  theme_minimal() +
  labs(title = "t-SNE colored by HER2 status",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR PGR STATUS
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = factor(`pgr status:ch1`))) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_manual(values = c("steelblue", "firebrick"), labels = c("No", "Yes")) +
  theme_minimal() +
  labs(title = "t-SNE colored by PGR status",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR AGE AT DIAGNOSIS
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = `age at diagnosis:ch1`)) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_viridis_c(option = "plasma") +
  theme_minimal() +
  labs(title = "t-SNE colored by Age at Diagnosis",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR OVERALL SURVIVAL DAYS
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = `overall survival days:ch1`)) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_viridis_c(option = "plasma") +
  theme_minimal() +
  labs(title = "t-SNE colored by overall survival days",
       x = "t-SNE 1", y = "t-SNE 2")
#PLOT FOR TUMOR SIZE
ggplot(tsne_merged, aes(x = TSNE1, y = TSNE2, color = `tumor size:ch1`)) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_viridis_c(option = "plasma") +
  theme_minimal() +
  labs(title = "t-SNE colored by tumor size",
       x = "t-SNE 1", y = "t-SNE 2")

#checking for outliers



#testing hypothesis with Cox model
merged_data_2$`chemo treated:ch1`<- as.factor(merged_data_2$`chemo treated:ch1`)
merged_data_2$`overall survival event:ch1` <- as.numeric(merged_data_2$`overall survival event:ch1`)
merged_data_2$`overall survival days:ch1` <- as.numeric(merged_data_2$`overall survival days:ch1`)

library(survival)
cox_model <- coxph(Surv(`overall survival days:ch1`, `overall survival event:ch1`) ~ 
                   ESR1 * `chemo treated:ch1` + `age at diagnosis:ch1` + `tumor size:ch1` + `er status:ch1` + `her2 status:ch1` + `pgr status:ch1`, 
                   data = merged_data_2)
summary(cox_model)

library(survminer)
ggsurvplot(survfit(cox_model), data = merged_data_2, risk.table = TRUE)


###machine learning (python)

#load packages

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.metrics import confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier


sns.set_style("whitegrid")
sns.set_palette("deep")

%matplotlib inline

#Read in Breast cancer dataset
df = pd.read_csv("GSE96058_expression_matrix_3decimals_new.tsv", sep="\t", header=None)
dfmeta = pd.read_csv("GSE96058_metadata.txt", sep="\t")

#merge data 

df=df.T
df.columns = df.iloc[0]
df = df.iloc[1:]
first_col = df.columns[0]
df = df.set_index(first_col)
dfmeta = dfmeta.set_index("title")
dfmeta.index.name = None
combined = df.join(dfmeta, how="inner")
combined.head()

#impute missing values and remove ki67

combined = combined.drop(columns=["ki67 status:ch1"])
from sklearn.impute import KNNImputer
numeric_cols = combined.select_dtypes(include=['float64','int64']).columns
categorical_cols = combined.select_dtypes(exclude=['float64','int64']).columns
imputer = KNNImputer(n_neighbors=5)
combined[numeric_cols] = imputer.fit_transform(combined[numeric_cols])

#only use certain ER values (0 or 1)

mask = combined["er status:ch1"].isin([0.0, 1.0])
combined_bin = combined.loc[mask].copy()
y = combined_bin["er status:ch1"].astype(int)

#split the data

#model 1

genes_A = ["ESR1"]
X_A = combined_bin[genes_A]
X_A_train, X_A_test, y_train, y_test = train_test_split(
    X_A, y, test_size=0.2, random_state=42, stratify=y
)
#model 2

X_all = combined_bin[gene_cols].apply(pd.to_numeric, errors="coerce")
X_train, X_test, y_train, y_test = train_test_split(
    X_all, y, test_size=0.2, random_state=42, stratify=y
)

#standaardiseren 

#model 1

scaler = StandardScaler()
scaler.fit(X_A_train)                  
train_A_scaled = scaler.transform(X_A_train)
test_A_scaled = scaler.transform(X_A_test)

#model 2: take first the 500 most variabele genes

variances = X_train.var(axis=0)
top500 = variances.sort_values(ascending=False).head(500).index
X_train_500 = X_train[top500]
X_test_500 = X_test[top500]
scaler = StandardScaler()
scaler.fit(X_train_500)
X_train_500_scaled = scaler.transform(X_train_500)
X_test_500_scaled = scaler.transform(X_test_500)

#logistic regression 

#model 1

clf_A = LogisticRegression(max_iter=500)
clf_A.fit(train_A_scaled, y_train)
prob_A = clf_A.predict_proba(test_A_scaled)[:, 1]

print("=== MODEL A (ESR1 only) ===")
print("AUC:", roc_auc_score(y_test, prob_A))
print(classification_report(y_test, (prob_A >= 0.5).astype(int)))

#model 2

clf_C = LogisticRegression(max_iter=1000)
clf_C.fit(X_train_500_scaled, y_train)
prob_C = clf_C.predict_proba(X_test_500_scaled)[:, 1]

print("=== MODEL C (Top 500 variabele genen) ===")
print("AUC:", roc_auc_score(y_test, prob_C))
print(classification_report(y_test, (prob_C >= 0.5).astype(int)))

#neural network

#model 1

print("========== MLP NEURAL NETWORK ==========")
alphas = [0.0001, 0.001, 0.01]
best_auc_A = -1
best_alpha_A = None
best_prob_A_mlp = None

for a in alphas:
    mlp_A = MLPClassifier(
        hidden_layer_sizes=(100, 50),
        alpha=a,
        max_iter=1000,
        random_state=42
    )
    mlp_A.fit(train_A_scaled, y_train)
    prob = mlp_A.predict_proba(test_A_scaled)[:, 1]
    auc = roc_auc_score(y_test, prob)
    if auc > best_auc_A:
        best_auc_A = auc
        best_alpha_A = a
        best_prob_A_mlp = prob

print("=== MLP MODEL A (ESR1 only) ===")
print("Beste alpha:", best_alpha_A)
print("AUC:", best_auc_A)
print(classification_report(y_test, (best_prob_A_mlp >= 0.5).astype(int)))

#model 2

alphas = [0.0001, 0.001, 0.01]
best_auc = -1
best_alpha = None
best_prob = None

for a in alphas:
    mlp_500 = MLPClassifier(
        hidden_layer_sizes=(100, 50),
        alpha=a,
        max_iter=1000,
        random_state=42
    )
    mlp_500.fit(X_train_500_scaled, y_train)
    prob = mlp_500.predict_proba(X_test_500_scaled)[:, 1]
    auc = roc_auc_score(y_test, prob)

    if auc > best_auc:
        best_auc = auc
        best_alpha = a
        best_prob = prob

print("=== MODEL C – Neural Network (500 genen) ===")
print("Beste alpha:", best_alpha)
print("AUC:", best_auc)
print(classification_report(y_test, (best_prob >= 0.5).astype(int)))

#random forest

#model 1

print("========== RANDOM FOREST ==========")
rf_A = RandomForestClassifier(
    n_estimators=500,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1,
    class_weight="balanced"   # omdat er veel meer ER+ dan ER- zijn
)
rf_A.fit(X_A_train, y_train)
prob_A_rf = rf_A.predict_proba(X_A_test)[:, 1]

print("=== RF MODEL A (ESR1 only) ===")
print("AUC:", roc_auc_score(y_test, prob_A_rf))
print(classification_report(y_test, (prob_A_rf >= 0.5).astype(int)))

#model 2

rf_500 = RandomForestClassifier(
    n_estimators=500,
    min_samples_leaf=5,
    random_state=42,
    class_weight="balanced",
    n_jobs=-1
)

rf_500.fit(X_train_500, y_train)
prob_500_rf = rf_500.predict_proba(X_test_500)[:, 1]

print("=== MODEL C – Random Forest (500 genen) ===")
print("AUC:", roc_auc_score(y_test, prob_500_rf))
print(classification_report(y_test, (prob_500_rf >= 0.5).astype(int)))

#confusion matrix

#model 1

y_test_pred = (prob_A >= 0.5).astype(int)
cm = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=sorted(y_test.unique()),
            yticklabels=sorted(y_test.unique()))
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix - Model 1 (ESR1)', fontsize=14)
plt.show()

#model 2

y_pred_500 = (prob_500_rf >= 0.5).astype(int)
cm = confusion_matrix(y_test, y_pred_500)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=sorted(y_test.unique()),
            yticklabels=sorted(y_test.unique()))
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix – Model 2 (Random Forest, 500 genes)', fontsize=14)
plt.show()




